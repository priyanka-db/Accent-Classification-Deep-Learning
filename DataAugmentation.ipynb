{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataAugmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LuieFv6X656",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd       \n",
        "import os \n",
        "import math \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  \n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import librosa\n",
        "import librosa.display\n",
        "import time\n",
        "import warnings\n",
        "import pickle as pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AGX9u5QaZjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/recordings.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSAJEQn4aIrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLE_RATE = 22050\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv(\"drive/My Drive/aug_speakers.csv\")\n",
        "df.drop(df.columns[9:12],axis = 1, inplace = True)\n",
        "print(df.columns)\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxgvo1NNZr5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "samples_count = collections.Counter(df[\"native_language\"].values)\n",
        "new_d = {}\n",
        "for key,val in samples_count.items():\n",
        "    new_d[val] = new_d.get(val,[])+[key]\n",
        "\n",
        "for i in range(8):\n",
        "    if i in new_d.keys():\n",
        "        del new_d[i]\n",
        "\n",
        "# print(new_d)\n",
        "sorted_d = {k: v for k, v in sorted(new_d.items(), key=lambda item: item[0])}\n",
        "classes = []\n",
        "for _,val in sorted_d.items():\n",
        "    classes+=val\n",
        "sorted_d.clear()\n",
        "new_d.clear()\n",
        "\n",
        "# print(total)\n",
        "# print(len(classes))\n",
        "# {k: v for k, v in sorted(new_d.items(), key=lambda item: item[0])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMq2uao_YWRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def run_function(func,data,sampling_rate,age,sex):\n",
        "    if func == \"pitch\":\n",
        "        if sex == \"male\":\n",
        "            y = librosa.effects.pitch_shift(data, sampling_rate, n_steps=4)\n",
        "        else:\n",
        "            y = librosa.effects.pitch_shift(data, sampling_rate, n_steps=-4)\n",
        "    elif func == \"faster\":\n",
        "        y = librosa.effects.time_stretch(data, 2.0)\n",
        "    elif func == \"slower\":\n",
        "        y = librosa.effects.time_stretch(data, 0.5)\n",
        "    return y\n",
        "\n",
        "\n",
        "def trim_pad(data):\n",
        "    sr_dur = 22050*18\n",
        "    if 0 < len(data): \n",
        "        y, _ = librosa.effects.trim(data) \n",
        "        trim_long_data = True\n",
        "        if len(y) > sr_dur: \n",
        "            if trim_long_data:\n",
        "                y = y[0:0+sr_dur]\n",
        "        else: \n",
        "            padding = sr_dur - len(y)    \n",
        "            offset = padding // 2\n",
        "            y = np.pad(y, (offset, sr_dur - len(y) - offset), 'constant')\n",
        "        return y\n",
        "    return data\n",
        "     \n",
        "\n",
        "def append_new_row_to_df(new_row_data,file_counter):   \n",
        "#     print(\"in append_new_data_to_df\")\n",
        "#     print(new_row_data)\n",
        "    with open('drive/My Drive/aug_speakers.csv','a',newline='') as f:\n",
        "        writer=csv.writer(f)\n",
        "        new_row_data[3] = new_row_data[4]+str(file_counter)\n",
        "        writer.writerow(new_row_data)\n",
        "#     print(\"out append_new_data_to_df\")\n",
        "    \n",
        "\n",
        "func_list = [\"pitch\",\"faster\",\"slower\"]\n",
        "except_flag = False\n",
        "for j,label in enumerate(classes):\n",
        "    print(j+1,label)\n",
        "    lang_df = df.loc[df['native_language'] == label]\n",
        "    row_datas = []\n",
        "    for _,row in lang_df.iterrows():\n",
        "        if not row['file_missing?']:\n",
        "            try:\n",
        "                path = 'recordings/' + row['filename'] +\".mp3\"\n",
        "                data, sampling_rate = librosa.load(path, sr=SAMPLE_RATE, duration=18)\n",
        "                row_datas.append([data,sampling_rate,row.values])\n",
        "            except Exception:\n",
        "                print(\"exception at filename \"+row['filename']) \n",
        "\n",
        "    row_datas_exists = len(row_datas)\n",
        "    if row_datas_exists: #Means there was no exception when loading the file\n",
        "        for func in func_list:\n",
        "            i = 0\n",
        "            new_row_datas = []\n",
        "            while i < len(row_datas) and (len(row_datas)+i) < 50:\n",
        "                new_data = run_function(func,row_datas[i][0],row_datas[i][1],row_datas[i][2][0],row_datas[i][2][5])\n",
        "                new_row_datas.append([new_data,row_datas[i][1],row_datas[i][2].copy()])\n",
        "                append_new_row_to_df(row_datas[i][2].copy(),len(row_datas)+i+1) #define this function\n",
        "                i+=1\n",
        "            row_datas += new_row_datas\n",
        "        row_datas = row_datas[:50]\n",
        "        print(len(row_datas))\n",
        "        pickle_counter = 0\n",
        "        for row_data in row_datas:\n",
        "            trim_padded_y = trim_pad(row_data[0])\n",
        "            mfcc = librosa.feature.mfcc(y=trim_padded_y, sr=sampling_rate, n_mfcc = 40)\n",
        "            melspec = librosa.feature.melspectrogram(trim_padded_y, sr=sampling_rate, n_mels=128)\n",
        "            save_data={\"data\": trim_padded_y,\"sampling_rate\":sampling_rate,\"mfcc\": mfcc,\"melspec\":melspec}\n",
        "            pickle_counter+=1\n",
        "            with open('Augmented_Features/'+row['native_language']+str(pickle_counter)+'.pkl', 'wb') as outfile:\n",
        "                pickle.dump(save_data, outfile, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}